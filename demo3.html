<!DOCTYPE html>
<html lang="en">
  <head>
    <link rel="stylesheet" href="demo03.css" />
    <title>mydemo3</title>
  </head>
  <body>
    <div class="container">
      <center><h4>MIND READING-SYSTEM</h4></center>
      <div class="subdiv">
        <p>
          People express their mental states, including emotions, thoughts, and
          desires, all the time through facial expressions, vocal nuances and
          gestures. This is true even when they are interacting with machines.
          Our mental states shape the decisions that we make, govern how we
          communicate with others, and affect our performance. The ability to
          attribute mental states to others from their behaviour, and to use
          that knowledge to guide our own actions and predict those of others is
          known as theory of mind or mind-reading. It has recently gained
          attention with the growing number of people with Autism Spectrum
          Conditions, who have difficulties mind-reading. Existing
          human-computer interfaces are mind-blind — oblivious to the user’s
          mental states and intentions. A computer may wait indefinitely for
          input from a user who is no longer there, or decide to do irrelevant
          tasks while a user is frantically working towards an imminent
          deadline. As a result, existing computer technologies often frustrate
          the user, have little persuasive power and cannot initiate
          interactions with the user. Even if they do take the initiative, like
          the now retired Microsoft Paperclip, they are often misguided and
          irrelevant, and simply frustrate the user. With the increasing
          complexity of computer technologies and the ubiquity of mobile and
          wearable devices, there is a need for machines that are aware of the
          user’s mental state and that adaptively respond to these mental
          states.
        </p>
        <img
          src="https://images.unsplash.com/photo-1618590748055-9bb934ef0055?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=387&q=80"
          class="demo2"
        />
      </div>
      <h3 class="demo4"><b>A computational model of mind-reading</b></h3>
      <p>
        Using a digital video camera, the mind-reading computer system analyzes
        a person’s facial expressions in real time and infers that person’s
        underlying mental state, such as whether he or she is agreeing or
        disagreeing, interested or bored, thinking or confused. The system is
        informed by the latest developments in the theory of mind-reading by
        Professor Simon Baron-Cohen, who leads the Autism Research Centre at
        Cambridge. Prior knowledge of how particular mental states are expressed
        in the face is combined with analysis of facial expressions and head
        gestures occurring in real time. The model represents these at different
        granularities, starting with face and head movements and building those
        in time and in space to form a clearer model of what mental state is
        being represented. Software from Nevenvision identifies 24 feature
        points on the face and tracks them in real time. Movement, shape and
        colour are then analyzed to identify gestures like a smile or eyebrows
        being raised. Combinations of these occurring over time indicate mental
        states. For example, a combination of a head nod, with a smile and
        eyebrows raised might mean interest. The relationship between observable
        head and facial displays and the corresponding hidden mental states over
        time is modelled using Dynamic Bayesian Networks.
      </p>
      <ul>
        <li>
          It involves uncertainty, since a person’s mental state can only be
          inferred indirectly by analyzing the behaviour of that person. Even
          people are not perfect at reading the minds of others.
        </li>
        <li>
          Automatic analysis of the face from video is still an area of active
          research in its own right.
        </li>
        <li>
          There is no ‘code-book’ to interpret facial expressions as
          corresponding mental states.
        </li>
      </ul>
      <h2 class="demo1">contact us</h2>
    </div>
  </body>
</html>
